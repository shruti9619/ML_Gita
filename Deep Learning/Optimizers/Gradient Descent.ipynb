{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In calculus when we want to minimize or maximize the value of a function, we take it's first derivative and set it's value to 0. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably this is too far into the trek without reaching the basecamp. So let's reach the basecamp first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need a model when we have the data points that we can use to infer the patterns? We need a model on those data points (perhaps also with some regularization and bias considerations) because we are not aware of the actual function that created that data. We are only trying to guess what that original function could have been. This guess is our model.\n",
    "\n",
    "When we have a function that defines our model (a.k.a the hypothesis) we realise that the function could take so many values for the different weights/parameters we have and it is not a good idea to go with the first set of values for the weights that seem decent enough. Since we are defining a hypothesis, we don't know the actual function that generated that data, at least we should define the best one possible which, by best, I mean it fits the data the best it can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we measure the performance of difference models (varying weights) for the given data?\n",
    "\n",
    "A cost/loss function is something that defines the value of error in estimations of the model/function/hypothesis. So then we basically need to minimize the loss function in order for the errors between the actual and predicted values to be lower. Now what could we change in the model to change the value of the predictions and bring it closer to actual values? Of course, the weights! Don't forget, the hypothesis/model is a function of the data and the weights don't change for one hypothesis, it gives us the predicted values whereas the cost function is a function of different weight values and it gives us the estimated error/loss between actuals and predicted values given that particular choice of weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So then how do we figure out which function fits the data the best? By trying out different weights for that function, where each set of weights would give us a different estimate of the error and we choose the one where the error is the least. This error is also called loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But! \n",
    "\n",
    "How do we know which weights to choose? Do we try all the available numbers in the world? Is that computationally possible? No!\n",
    "\n",
    "Enter **Gradient Descent**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
