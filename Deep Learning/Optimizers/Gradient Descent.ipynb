{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In calculus when we want to minimize or maximize the value of a function, we take it's first derivative and set it's value to 0. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably this is too far into the trek without reaching the basecamp. So let's reach the basecamp first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need a model when we have the data points that we can use to infer the patterns? We need a model on those data points (perhaps also with some regularization and bias considerations) because we are not aware of the actual function that created that data. We are only trying to guess what that original function could have been. This guess is our model.\n",
    "\n",
    "When we have a function that defines our model (a.k.a the hypothesis) we realise that the function could take so many values for the different weights/parameters we have and it is not a good idea to go with the first set of values for the weights that seem decent enough. Since we are defining a hypothesis, we don't know the actual function that generated that data, at least we should define the best one possible which, by best, I mean it fits the data the best it can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we measure the performance of difference models (varying weights) for the given data?\n",
    "\n",
    "A cost/loss function is something that defines the value of error in estimations of the model/function/hypothesis. So then we basically need to minimize the loss function in order for the errors between the actual and predicted values to be lower. Now what could we change in the model to change the value of the predictions and bring it closer to actual values? Of course, the weights! Don't forget, the hypothesis/model is a function of the data and the weights don't change for one hypothesis, it gives us the predicted values whereas the cost function is a function of different weight values and it gives us the estimated error/loss between actuals and predicted values given that particular choice of weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So then how do we figure out which function fits the data the best? By trying out different weights for that function, where each set of weights would give us a different estimate of the error and we choose the one where the error is the least. This error is also called loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But! \n",
    "\n",
    "How do we know which weights to choose? Do we try all the available numbers in the world? Is that computationally possible? No!\n",
    "\n",
    "Enter **Gradient Descent**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm used to determine the values of parameters (coefficients) of a function \\( f \\) that minimize a cost function.\n",
    "\n",
    "It is particularly effective when the parameters cannot be calculated analytically (e.g., using linear algebra) and must instead be found through an optimization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a cost function which is dependent on a single weight value w, shown below:\n",
    "\n",
    "\n",
    "( add image here)\n",
    "\n",
    "\n",
    "\n",
    "On the x-axis is w and on the y-axis we have the cost function. The curve depicts the different values of cost function \\( f \\) for different values of w. Remember this is the same cost function that we wanted to minimize but didn't know what is the exact value of w that brings it to its minimum value.\n",
    "\n",
    "Here we can visually observe that point but how do we navigate our w value towards it programmatically?\n",
    "\n",
    "Enter **Calculus**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we get to the lowest point in that curve that gives us the minimum error and gives us the weights values that occur at that point?\n",
    "\n",
    "### Presenting!!!\n",
    "#### How Gradient Descent Works\n",
    "\n",
    "1. **Initialization**: Start with initial guesses for the parameters. These can be random values or zeros.\n",
    "2. **Compute the Gradient**: Calculate the gradient (partial derivatives) of the cost function with respect to each parameter. The gradient indicates the direction and rate of fastest increase of the cost function.\n",
    "3. **Update the Parameters**: Adjust the parameters in the opposite direction of the gradient. This step is repeated iteratively until the cost function converges to a minimum value.\n",
    "\n",
    "    \\[\n",
    "    \\theta = \\theta - \\alpha \\nabla J(\\theta)\n",
    "    \\]\n",
    "\n",
    "    Where:\n",
    "    - \\( \\theta \\) represents the parameters.\n",
    "    - \\( \\alpha \\) is the learning rate, a small positive number that controls the step size.\n",
    "    - \\( \\nabla J(\\theta) \\) is the gradient of the cost function \\( J \\) with respect to \\( \\theta \\).\n",
    "\n",
    "4. **Convergence**: The algorithm stops when the cost function reaches a minimum value, which means the parameters are optimized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "So let's say we randomly chose a value for w which lands us at point A on the curve for the loss function. Fine, the next step is to compute the gradient with respect to w.\n",
    "\n",
    "But what really is a gradient?\n",
    "\n",
    "A gradient is a vector that points in the direction of the steepest increase of a function and its magnitude represents the rate of increase. Basically in 2-D it can be called the slope that we used to study in school. In a geometric sense, it generalizes the concept of slope to multiple dimensions. The visualization shows the same \n",
    "\n",
    "(3rd quadrant pic)\n",
    "\n",
    "(PS: A tangent line or plane touches a curve or surface at a single point and has the same slope or direction as the curve or surface at that point.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Types of Gradient Descent\n",
    "\n",
    "1. **Batch Gradient Descent**: Uses the entire dataset to compute the gradient at each step. It provides accurate updates but can be computationally expensive for large datasets.\n",
    "2. **Stochastic Gradient Descent (SGD)**: Uses one data point at a time to compute the gradient. It is much faster and can escape local minima, but it introduces more noise in the parameter updates.\n",
    "3. **Mini-Batch Gradient Descent**: A compromise between batch and stochastic gradient descent. It uses a small random subset of the data (mini-batch) to compute the gradient. It balances the efficiency and accuracy of updates.\n",
    "\n",
    "#### When to Use Gradient Descent\n",
    "\n",
    "Gradient descent is particularly useful when:\n",
    "\n",
    "1. **Analytical Solutions are Infeasible**: For many complex models, the parameters cannot be calculated analytically using linear algebra or other closed-form solutions. Gradient descent provides a numerical solution.\n",
    "2. **High-Dimensional Data**: It is effective in optimizing models with a large number of parameters, which is common in deep learning.\n",
    "3. **Non-Convex Functions**: Gradient descent can handle non-convex cost functions often encountered in neural networks, where traditional optimization methods might fail.\n",
    "\n",
    "#### Practical Considerations\n",
    "\n",
    "1. **Learning Rate**: Choosing an appropriate learning rate is crucial. A learning rate that is too high can cause the algorithm to diverge, while a learning rate that is too low can make convergence very slow.\n",
    "2. **Feature Scaling**: Preprocessing the data to ensure that features are on a similar scale can significantly improve the performance of gradient descent.\n",
    "3. **Regularization**: Adding regularization terms to the cost function can prevent overfitting and improve generalization.\n",
    "\n",
    "In summary, gradient descent is a versatile and powerful optimization algorithm that is essential for training a wide variety of machine learning models, especially when dealing with large datasets and complex functions. By iteratively updating parameters in the direction that reduces the cost function, gradient descent helps in finding the optimal solution that best fits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
